<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Convolutional Neural Networks - CNNs | Adil&#39;s Notes</title>
<meta name="keywords" content="Beginner, Neural Networks, CNN, Convolution">
<meta name="description" content="What is the convolutional neural network?">
<meta name="author" content="">
<link rel="canonical" href="https://adilsarsenov.dev/posts/convolutional-neural-networks/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.a72801f0f40a8d7f71aa1cafd1c2f2a993a1f26ca1cfd38fdba65d5b9b0f08a0.css" integrity="sha256-pygB8PQKjX9xqhyv0cLyqZOh8myhz9OP26ZdW5sPCKA=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js" integrity="sha256-uVus3DnjejMqn4g7Hni&#43;Srwf3KK8HyZB9V4809q9TWE="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://adilsarsenov.dev/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://adilsarsenov.dev/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://adilsarsenov.dev/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://adilsarsenov.dev/apple-touch-icon.png">
<link rel="mask-icon" href="https://adilsarsenov.dev/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Convolutional Neural Networks - CNNs" />
<meta property="og:description" content="What is the convolutional neural network?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adilsarsenov.dev/posts/convolutional-neural-networks/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-17T18:34:44&#43;05:00" />
<meta property="article:modified_time" content="2024-03-17T18:34:44&#43;05:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Convolutional Neural Networks - CNNs"/>
<meta name="twitter:description" content="What is the convolutional neural network?"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://adilsarsenov.dev/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Convolutional Neural Networks - CNNs",
      "item": "https://adilsarsenov.dev/posts/convolutional-neural-networks/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Convolutional Neural Networks - CNNs",
  "name": "Convolutional Neural Networks - CNNs",
  "description": "What is the convolutional neural network?",
  "keywords": [
    "Beginner", "Neural Networks", "CNN", "Convolution"
  ],
  "articleBody": "Convolutional Neural Networks (CNNs) are a class of deep learning models designed to process visual data.\nTensors: A tensor can be conceptualized as an N-dimensional matrix.\nNeurons: A neuron functions as a computational unit, receiving multiple inputs and generating a single output.\nLayers: A layer consists of a collection of neurons that perform the same operation, sharing identical hyperparameters.\nKernel weights and biases: Unique to each neuron, kernel weights and biases are adjusted during the training process, enabling the classifier to adapt to the specific problem and dataset.\nKey Concepts of CNN Components Convolutional Layer The convolutional layer applies filter(kernel) to the input image to extract features like edges and textures.\nConvolutional Layer: The primary building block of a CNN, responsible for feature extraction. Filter (Kernel): A small matrix that slides over the input image, performing multiplications and summations to produce a feature map. Feature Map (Activation Map): The result of the convolution operation, highlighting important features such as edges, textures, and patterns. Convolution operation allows the network to learn spatial hierarchies of features automatically from low-level to high-level.\n$$ (I * K)(i, j) = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} I(i + m, j + n) K(m, n) $$\n$( I )$: Input image $( K )$: Kernel (filter) $( (i, j) )$: Coordinates in the output feature map $( M, N )$: Dimensions of the kernel Understanding Hyperparameters Kernel Size: Dimensions of the filter (e.g., 3x3, 5x5). Affects the amount of detail the filter can capture. Stride: Step size of the filter movement. Larger strides reduce the output size but increase computational efficiency. Padding: Adds zeros around the input image to maintain the output size. “Valid” means no padding, “same” keeps the output size the same as the input. Non-Linearity (ReLU) Activation Function ReLU (Rectified Linear Unit): Introduces non-linearity to the model. It replaces negative values with zero, allowing the network to learn complex patterns. Activation function decides whether the neuron must be activated or not. So it means whether the neuron’s input is important to the network or not. $$ \\text{ReLU}(x) = \\begin{cases} x \u0026 \\text{if } x \u003e 0 \\\\ 0 \u0026 \\text{otherwise} \\end{cases} $$\nBy setting negative values to zero, ReLU prevents the network from simply becoming a linear classifier.\nAnother popular activation functions:\nPooling Layers Reduces computational complexity and helps the network become invariant to small translations of the input image.\nMax-Pooling: operation requires selecting a kernel size and a stride length. Once selected, the operation slides the kernel with the specified stride over the input retaining the most important information by selecting the maximum value within each window, effectively down-sampling the feature map. $$ Y(i, j) = \\max_{m,n} X(i \\cdot s + m, j \\cdot s + n) $$\n$( X )$: Input feature map $( Y )$: Output feature map $( s )$: Stride $( m, n )$: Window dimensions Pooling prevents overfitting.\nFlattening Flatten Layer: Converts the 2D pooled feature maps into a 1D vector for the fully connected layers. The flattened vector is fed as input to the fully connected layer to classify the image. Fully Connected Layer The Fully Connected Layer, also known as the dense layer, is the final layer that comes after the convolutional and pooling layers. Its purpose is to perform classification or regression tasks based on the high-level features extracted by the earlier layers of the network. In FC, all the neurons of the input are connected to every neuron of the output layer.\nFormula: $$ y = f(W \\cdot x + b) $$\n$( W )$: Weight matrix $( x )$: Input vector $( b )$: Bias vector $( f )$: Activation function The fully connected layer combines the high-level features learned by the convolutional layers to output a final prediction.\nOutput Layer The output layer is typically a softmax layer in classification tasks. The softmax function converts the raw output scores into probabilities.\nSoftmax Function: $$ \\sigma(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} $$\n$( z_i )$: The (i)-th element of the input vector $(z)$ $( K )$: Number of classes The softmax function ensures that the output probabilities sum to 1, making it easier to interpret the results as the likelihood of each class.\nSimple Example of CNN Architecture Here’s a simple CNN architecture for image classification:\nInput Layer: 28x28 grayscale image Convolutional Layer: conv layer with filter of the size 5x5, with valid padding(no padding), the feature maps have a size of 24x24xn1, where n1 is the number of filters used in this layer. Max-Pooling Layer: 2x2 window, stride 2 Convolutional Layer: conv layer with filter of the size 5x5, with valid padding(no padding) Max-Pooling Layer: 2x2 window, stride 2 Flatten Layer: Converts the feature maps 4x4 into a 1D vector with total size of 4x4xn2. Fully Connected Layer: the flattened vector is passed through a fully connected layer with n3 units, with ReLU activation function. Fully Connected Layer: passed again, applies Dropout to prevent overfitting Output Layer: Final Fully Connected Layer, which has 10 units corresponding to the 10 possible digit classes (0-9). This example illustrates the typical workflow in a CNN, from input to final classification.\n",
  "wordCount" : "850",
  "inLanguage": "en",
  "datePublished": "2024-03-17T18:34:44.165668+05:00",
  "dateModified": "2024-03-17T18:34:44.165668+05:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://adilsarsenov.dev/posts/convolutional-neural-networks/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Adil's Notes",
    "logo": {
      "@type": "ImageObject",
      "url": "https://adilsarsenov.dev/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top"><script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header sticky-header">
    <nav class="nav">
        <div class="logo">
            <a href="https://adilsarsenov.dev/" accesskey="h" title="Adil&#39;s Notes (Alt + H)">Adil&#39;s Notes</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://adilsarsenov.dev/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://adilsarsenov.dev/">Home</a>&nbsp;»&nbsp;<a href="https://adilsarsenov.dev/posts/">Posts</a></div>
    <h1 class="post-title">
      Convolutional Neural Networks - CNNs
    </h1>
    <div class="post-description">
      What is the convolutional neural network?
    </div>
    <div class="post-meta">


Date: 17 March, 2024

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">‎ Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#key-concepts-of-cnn-components" aria-label="Key Concepts of CNN Components">Key Concepts of CNN Components</a><ul>
                        
                <li>
                    <a href="#convolutional-layer" aria-label="Convolutional Layer">Convolutional Layer</a></li>
                <li>
                    <a href="#understanding-hyperparameters" aria-label="Understanding Hyperparameters">Understanding Hyperparameters</a></li>
                <li>
                    <a href="#non-linearity-relu-activation-function" aria-label="Non-Linearity (ReLU) Activation Function">Non-Linearity (ReLU) Activation Function</a></li>
                <li>
                    <a href="#pooling-layers" aria-label="Pooling Layers">Pooling Layers</a></li>
                <li>
                    <a href="#flattening" aria-label="Flattening">Flattening</a></li>
                <li>
                    <a href="#fully-connected-layer" aria-label="Fully Connected Layer">Fully Connected Layer</a></li>
                <li>
                    <a href="#output-layer" aria-label="Output Layer">Output Layer</a></li>
                <li>
                    <a href="#simple-example-of-cnn-architecture" aria-label="Simple Example of CNN Architecture">Simple Example of CNN Architecture</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><strong>Convolutional Neural Networks (CNNs)</strong> are a class of deep learning models designed to process visual data.</p>
<p><strong>Tensors:</strong> A tensor can be conceptualized as an <strong>N-dimensional</strong> matrix.</p>
<p><strong>Neurons:</strong> A neuron functions as a computational unit, receiving <strong>multiple inputs and generating a single output</strong>.</p>
<p><strong>Layers:</strong> A layer consists of a <strong>collection of neurons</strong> that perform the same operation, sharing identical hyperparameters.</p>
<p><strong>Kernel weights and biases:</strong> Unique to each neuron, kernel weights and biases are adjusted during the training process,
enabling the classifier to adapt to the specific problem and dataset.</p>
<h2 id="key-concepts-of-cnn-components">Key Concepts of CNN Components<a hidden class="anchor" aria-hidden="true" href="#key-concepts-of-cnn-components">#</a></h2>
<h3 id="convolutional-layer">Convolutional Layer<a hidden class="anchor" aria-hidden="true" href="#convolutional-layer">#</a></h3>
<p>The convolutional layer applies filter(kernel) to the input image to extract features like edges and textures.</p>
<ul>
<li><strong>Convolutional Layer:</strong> The primary building block of a CNN, responsible for feature extraction.</li>
<li><strong>Filter (Kernel):</strong> A small matrix that slides over the input image, performing multiplications and summations to produce a feature map.</li>
<li><strong>Feature Map (Activation Map):</strong> The result of the convolution operation, highlighting important features such as edges, textures, and patterns.</li>
</ul>
<p><strong>Convolution operation</strong>  allows the network to learn spatial hierarchies of features automatically from low-level to high-level.</p>
<p>$$
(I * K)(i, j) = \sum_{m=0}^{M-1} \sum_{n=0}^{N-1} I(i + m, j + n) K(m, n)
$$</p>
<ul>
<li>$( I )$: Input image</li>
<li>$( K )$: Kernel (filter)</li>
<li>$( (i, j) )$: Coordinates in the output feature map</li>
<li>$( M, N )$: Dimensions of the kernel</li>
</ul>
<p><img loading="lazy" src="/posts/convolutional-neural-networks/img2.png" alt="Convolution"  />
</p>
<h3 id="understanding-hyperparameters">Understanding Hyperparameters<a hidden class="anchor" aria-hidden="true" href="#understanding-hyperparameters">#</a></h3>
<ul>
<li><strong>Kernel Size:</strong> Dimensions of the filter (e.g., 3x3, 5x5). Affects the amount of detail the filter can capture.</li>
<li><strong>Stride:</strong> Step size of the filter movement. Larger strides reduce the output size but increase computational efficiency.</li>
<li><strong>Padding:</strong> Adds zeros around the input image to maintain the output size. &ldquo;Valid&rdquo; means no padding, &ldquo;same&rdquo; keeps the output size the same as the input.</li>
</ul>
<h3 id="non-linearity-relu-activation-function">Non-Linearity (ReLU) Activation Function<a hidden class="anchor" aria-hidden="true" href="#non-linearity-relu-activation-function">#</a></h3>
<ul>
<li><strong>ReLU (Rectified Linear Unit):</strong> Introduces non-linearity to the model. It replaces negative values with zero, allowing the network to learn complex patterns.
Activation function decides whether the neuron must be activated or not. So it means whether the neuron&rsquo;s input is important to the network or not.</li>
</ul>
<p>$$
\text{ReLU}(x) =
\begin{cases}
x &amp; \text{if } x &gt; 0 \\
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<p>By setting negative values to zero, ReLU prevents the network from simply becoming a linear classifier.</p>
<p>Another popular activation functions:</p>
<p><img loading="lazy" src="/posts/convolutional-neural-networks/img1.png" alt="Activation"  />
</p>
<h3 id="pooling-layers">Pooling Layers<a hidden class="anchor" aria-hidden="true" href="#pooling-layers">#</a></h3>
<p>Reduces computational complexity and helps the network become invariant to small translations of the input image.</p>
<ul>
<li><strong>Max-Pooling:</strong> operation requires selecting a kernel size and a stride length. Once selected, the operation slides the kernel with the specified stride over the input retaining the most important information by selecting the maximum value within each window, effectively down-sampling the feature map.</li>
</ul>
<p>$$
Y(i, j) = \max_{m,n} X(i \cdot s + m, j \cdot s + n)
$$</p>
<ul>
<li>$( X )$: Input feature map</li>
<li>$( Y )$: Output feature map</li>
<li>$( s )$: Stride</li>
<li>$( m, n )$: Window dimensions</li>
</ul>
<p><img loading="lazy" src="/posts/convolutional-neural-networks/img3.png" alt="MaxPooling"  />
</p>
<p>Pooling prevents <strong>overfitting</strong>.</p>
<h3 id="flattening">Flattening<a hidden class="anchor" aria-hidden="true" href="#flattening">#</a></h3>
<ul>
<li><strong>Flatten Layer:</strong> Converts the 2D pooled feature maps into a 1D vector for the fully connected layers.
The flattened vector is fed as input to the fully connected layer to classify the image.</li>
</ul>
<p><img loading="lazy" src="/posts/convolutional-neural-networks/img4.png" alt="Flattening"  />
</p>
<h3 id="fully-connected-layer">Fully Connected Layer<a hidden class="anchor" aria-hidden="true" href="#fully-connected-layer">#</a></h3>
<p><strong>The Fully Connected Layer</strong>, also known as the dense layer, is the final layer that comes after the convolutional and pooling layers.
Its purpose is to perform classification or regression tasks based on the high-level features extracted by the earlier layers of the network. In FC, all the neurons of the input are connected to every neuron of the output layer.</p>
<ul>
<li><strong>Formula:</strong></li>
</ul>
<p>$$
y = f(W \cdot x + b)
$$</p>
<ul>
<li>$( W )$: Weight matrix</li>
<li>$( x )$: Input vector</li>
<li>$( b )$: Bias vector</li>
<li>$( f )$: Activation function</li>
</ul>
<p>The fully connected layer combines the high-level features learned by the convolutional layers to output a final prediction.</p>
<p><img loading="lazy" src="/posts/convolutional-neural-networks/img5.png" alt="DenseLayer"  />
</p>
<h3 id="output-layer">Output Layer<a hidden class="anchor" aria-hidden="true" href="#output-layer">#</a></h3>
<p>The output layer is typically a softmax layer in classification tasks. The softmax function converts the raw output scores into probabilities.</p>
<ul>
<li><strong>Softmax Function:</strong></li>
</ul>
<p>$$
\sigma(z_i) = \frac{e^{z_i}}{\sum_{j=1}^K e^{z_j}}
$$</p>
<ul>
<li>$( z_i )$: The (i)-th element of the input vector $(z)$</li>
<li>$( K )$: Number of classes</li>
</ul>
<p>The softmax function ensures that the output probabilities sum to 1, making it easier to interpret the results as the likelihood of each class.</p>
<h3 id="simple-example-of-cnn-architecture">Simple Example of CNN Architecture<a hidden class="anchor" aria-hidden="true" href="#simple-example-of-cnn-architecture">#</a></h3>
<p>Here’s a simple CNN architecture for image classification:</p>
<ol>
<li><strong>Input Layer:</strong> 28x28 grayscale image</li>
<li><strong>Convolutional Layer:</strong> conv layer with filter of the size 5x5, with valid padding(no padding), the feature maps have a size of 24x24x<strong>n1</strong>, where <strong>n1</strong> is the number of filters used in this layer.</li>
<li><strong>Max-Pooling Layer:</strong> 2x2 window, stride 2</li>
<li><strong>Convolutional Layer:</strong> conv layer with filter of the size 5x5, with valid padding(no padding)</li>
<li><strong>Max-Pooling Layer:</strong> 2x2 window, stride 2</li>
<li><strong>Flatten Layer:</strong> Converts the feature maps 4x4 into a 1D vector with total size of <strong>4x4xn2</strong>.</li>
<li><strong>Fully Connected Layer:</strong> the flattened vector is passed through a fully connected layer with <strong>n3</strong> units, with ReLU activation function.</li>
<li><strong>Fully Connected Layer:</strong> passed again, applies <strong>Dropout</strong> to prevent overfitting</li>
<li><strong>Output Layer:</strong> Final Fully Connected Layer, which has 10 units corresponding to the 10 possible digit classes (0-9).</li>
</ol>
<p>This example illustrates the typical workflow in a CNN, from input to final classification.</p>
<p><img loading="lazy" src="/posts/convolutional-neural-networks/img6.jpeg" alt="ArchitectureCNN"  />
</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://adilsarsenov.dev/tags/beginner/">Beginner</a></li>
      <li><a href="https://adilsarsenov.dev/tags/neural-networks/">Neural Networks</a></li>
      <li><a href="https://adilsarsenov.dev/tags/cnn/">CNN</a></li>
      <li><a href="https://adilsarsenov.dev/tags/convolution/">Convolution</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://adilsarsenov.dev/">Adil&#39;s Notes</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>

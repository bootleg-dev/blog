<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>FCN and U-Net | Adil&#39;s Notes</title>
<meta name="keywords" content="Beginner, Image Segmentation, Deep Learning, FCN, Unet">
<meta name="description" content="Image Segmentation Techniques: FCN and U-Net.">
<meta name="author" content="">
<link rel="canonical" href="https://adilsarsenov.dev/posts/fcn-unet/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.a72801f0f40a8d7f71aa1cafd1c2f2a993a1f26ca1cfd38fdba65d5b9b0f08a0.css" integrity="sha256-pygB8PQKjX9xqhyv0cLyqZOh8myhz9OP26ZdW5sPCKA=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js" integrity="sha256-uVus3DnjejMqn4g7Hni&#43;Srwf3KK8HyZB9V4809q9TWE="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://adilsarsenov.dev/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://adilsarsenov.dev/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://adilsarsenov.dev/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://adilsarsenov.dev/apple-touch-icon.png">
<link rel="mask-icon" href="https://adilsarsenov.dev/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="FCN and U-Net" />
<meta property="og:description" content="Image Segmentation Techniques: FCN and U-Net." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adilsarsenov.dev/posts/fcn-unet/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-04-01T18:34:44&#43;05:00" />
<meta property="article:modified_time" content="2024-04-01T18:34:44&#43;05:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="FCN and U-Net"/>
<meta name="twitter:description" content="Image Segmentation Techniques: FCN and U-Net."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://adilsarsenov.dev/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "FCN and U-Net",
      "item": "https://adilsarsenov.dev/posts/fcn-unet/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "FCN and U-Net",
  "name": "FCN and U-Net",
  "description": "Image Segmentation Techniques: FCN and U-Net.",
  "keywords": [
    "Beginner", "Image Segmentation", "Deep Learning", "FCN", "Unet"
  ],
  "articleBody": "Introduction Image segmentation is a crucial technique in computer vision, enabling the division of an image into multiple meaningful and homogeneous regions or objects based on their inherent characteristics, such as color, texture, shape, or brightness. We delve into two powerful deep learning models for image segmentation: Fully Convolutional Networks (FCN) and U-Net.\nFully Convolutional Networks (FCN) Fully Convolutional Networks (FCNs) are a class of neural networks designed specifically for semantic segmentation. Unlike traditional Convolutional Neural Networks (CNNs) that produce a single label for the entire image, FCNs output a segmentation map where each pixel is classified into a particular category.\nArchitecture The architecture of an FCN is based on an encoder-decoder structure:\nEncoder (Downsampling Path): This part of the network extracts complex features from the input image through a series of convolutional and pooling layers. The spatial resolution is reduced while increasing the depth of the feature maps, allowing the network to capture high-level semantic information.\nDecoder (Upsampling Path): The decoder part of the network upscales the reduced-resolution feature maps back to the original image size. This is achieved through transposed convolution layers (also known as deconvolution layers), which learn the appropriate strides and padding to reconstruct the high-resolution segmentation map.\nKey Concepts Pooling (Downsampling): Pooling layers reduce the spatial resolution of the feature maps, which helps in capturing invariant features and reducing computational complexity. Common types include max pooling and average pooling. Unpooling (Upsampling): Pooling converts a patch of values to a single value, whereas unpooling does the opposite, converts a single value into a patch of values. Transposed Convolution (Upsampling): are used to increase the spatial resolution of the feature maps, essentially reversing the effect of pooling layers to reconstruct the detailed segmentation map. Skip Connections: One major issue with in-network downsampling in a FCN is that it reduces the resolution of the input by a large factor, thus during upsampling it becomes very difficult to reproduce the finer details even after using sophisticated techniques like Transpose Convolution. One-way to deal with this is by adding skip connections in the upsampling stage from earlier layers and summing the two feature maps. These connections transfer features from the encoder directly to the corresponding decoder layers, enabling the network to recover fine-grained details and produce more accurate segmentation boundaries.\nU-Net Overview U-Net is a specialized neural network architecture designed for biomedical image segmentation, introduced by Olaf Ronneberger, Philipp Fischer, and Thomas Brox in 2015. Its distinctive U-shaped design, which features a symmetric encoder-decoder structure, has made it a popular choice in various medical image analysis tasks due to its impressive performance and efficiency.\nArchitecture The U-Net architecture consists of two main parts:\nEncoder (Contraction Path): Similar to FCN, the encoder part of U-Net captures high-level features through a series of convolutional and pooling layers. Each block typically consists of two 3x3 convolution layers followed by a ReLU activation function and a 2x2 max pooling layer.\nDecoder (Expansion Path): The decoder part upscales the feature maps to the original image size using transposed convolutions. At each upsampling step, the decoder concatenates the feature maps from the corresponding encoder layer via skip connections, providing rich contextual information for precise segmentation.\nKey Concepts Skip Connections: By concatenating the feature maps from the encoder to the decoder at each corresponding level, U-Net can leverage both high-level and low-level features, resulting in better localization and segmentation accuracy.\nData Augmentation: Given the often limited availability of annotated data in medical imaging, U-Net heavily relies on data augmentation techniques to enhance the diversity of the training dataset. This includes operations like rotations, flips, and elastic deformations.\n",
  "wordCount" : "600",
  "inLanguage": "en",
  "datePublished": "2024-04-01T18:34:44.165668+05:00",
  "dateModified": "2024-04-01T18:34:44.165668+05:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://adilsarsenov.dev/posts/fcn-unet/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Adil's Notes",
    "logo": {
      "@type": "ImageObject",
      "url": "https://adilsarsenov.dev/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top"><script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header sticky-header">
    <nav class="nav">
        <div class="logo">
            <a href="https://adilsarsenov.dev/" accesskey="h" title="Adil&#39;s Notes (Alt + H)">Adil&#39;s Notes</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://adilsarsenov.dev/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://adilsarsenov.dev/">Home</a>&nbsp;»&nbsp;<a href="https://adilsarsenov.dev/posts/">Posts</a></div>
    <h1 class="post-title">
      FCN and U-Net
    </h1>
    <div class="post-description">
      Image Segmentation Techniques: FCN and U-Net.
    </div>
    <div class="post-meta">


Date: 01 April, 2024

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">‎ Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#fully-convolutional-networks-fcn" aria-label="Fully Convolutional Networks (FCN)">Fully Convolutional Networks (FCN)</a><ul>
                        
                <li>
                    <a href="#architecture" aria-label="Architecture">Architecture</a></li>
                <li>
                    <a href="#key-concepts" aria-label="Key Concepts">Key Concepts</a></li></ul>
                </li>
                <li>
                    <a href="#u-net" aria-label="U-Net">U-Net</a><ul>
                        
                <li>
                    <a href="#overview" aria-label="Overview">Overview</a></li>
                <li>
                    <a href="#architecture-1" aria-label="Architecture">Architecture</a></li>
                <li>
                    <a href="#key-concepts-1" aria-label="Key Concepts">Key Concepts</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h3>
<p>Image segmentation is a crucial technique in computer vision, enabling the division of an image into <strong>multiple meaningful and homogeneous regions
or objects based on their inherent characteristics, such as color, texture, shape, or brightness</strong>.
We delve into two powerful deep learning models for image segmentation:
Fully Convolutional Networks <strong>(FCN) and U-Net</strong>.</p>
<h3 id="fully-convolutional-networks-fcn">Fully Convolutional Networks (FCN)<a hidden class="anchor" aria-hidden="true" href="#fully-convolutional-networks-fcn">#</a></h3>
<p>Fully Convolutional Networks (FCNs) are a class of neural networks designed specifically for semantic segmentation. Unlike traditional Convolutional Neural Networks (CNNs) that produce a single label for the entire image, FCNs output a segmentation map where each pixel is classified into a particular category.</p>
<h4 id="architecture">Architecture<a hidden class="anchor" aria-hidden="true" href="#architecture">#</a></h4>
<p>The architecture of an FCN is based on an encoder-decoder structure:</p>
<p><img loading="lazy" src="/posts/unet/img1.png" alt="EncoderDecoderFCN"  />
</p>
<ol>
<li>
<p><strong>Encoder (Downsampling Path)</strong>: This part of the network extracts complex features from the input image through a series of convolutional and pooling layers. The spatial resolution is reduced while increasing the depth of the feature maps, allowing the network to capture high-level semantic information.</p>
</li>
<li>
<p><strong>Decoder (Upsampling Path)</strong>: The decoder part of the network upscales the reduced-resolution feature maps back to the original image size. This is achieved through <strong>transposed convolution layers (also known as deconvolution layers)</strong>, which learn the appropriate strides and padding to reconstruct the high-resolution segmentation map.</p>
</li>
</ol>
<p><img loading="lazy" src="/posts/unet/img2.png" alt="EncoderDecoderFCNCow"  />
</p>
<h4 id="key-concepts">Key Concepts<a hidden class="anchor" aria-hidden="true" href="#key-concepts">#</a></h4>
<ul>
<li><strong>Pooling (Downsampling)</strong>: Pooling layers reduce the spatial resolution of the feature maps, which helps in capturing invariant features and reducing computational complexity. Common types include max pooling and average pooling.</li>
</ul>
<p><img loading="lazy" src="/posts/unet/img3.jpeg" alt="Downsampling"  />
</p>
<ul>
<li><strong>Unpooling (Upsampling)</strong>: Pooling converts a patch of values to a single value, whereas <strong>unpooling does the opposite</strong>, converts a single value into a patch of values.</li>
</ul>
<p><img loading="lazy" src="/posts/unet/img4.png" alt="Downsampling"  />
</p>
<ul>
<li><strong>Transposed Convolution (Upsampling)</strong>: are used to increase the spatial resolution of the feature maps, essentially reversing the effect of pooling layers to reconstruct the detailed segmentation map.</li>
</ul>
<p><img loading="lazy" src="/posts/unet/img5.png" alt="DownsamplingTransposed"  />
</p>
<ul>
<li><strong>Skip Connections</strong>: One major issue with in-network downsampling in a FCN is that it <strong>reduces the resolution of the input by a large factor</strong>, thus during upsampling
it becomes very difficult to reproduce the <strong>finer details even after using sophisticated techniques like Transpose Convolution</strong>.</li>
</ul>
<p><img loading="lazy" src="/posts/unet/img6.png" alt="CoarseOutput"  />
</p>
<p>One-way to deal with this is by adding <strong>skip connections in the upsampling stage from earlier layers and summing the two feature maps</strong>.
These connections transfer features from the encoder <strong>directly to the corresponding decoder layers</strong>, enabling the network to recover fine-grained details and produce more accurate segmentation boundaries.</p>
<p><img loading="lazy" src="/posts/unet/img7.png" alt="SkipConns"  />
</p>
<h3 id="u-net">U-Net<a hidden class="anchor" aria-hidden="true" href="#u-net">#</a></h3>
<h4 id="overview">Overview<a hidden class="anchor" aria-hidden="true" href="#overview">#</a></h4>
<p>U-Net is a specialized neural network architecture designed for biomedical image segmentation,
introduced by <strong>Olaf Ronneberger, Philipp Fischer, and Thomas Brox in 2015</strong>. Its distinctive <strong>U-shaped design</strong>, which features a symmetric encoder-decoder structure, has made it a popular choice in various medical image analysis tasks due to its impressive performance and efficiency.</p>
<h4 id="architecture-1">Architecture<a hidden class="anchor" aria-hidden="true" href="#architecture-1">#</a></h4>
<p>The U-Net architecture consists of two main parts:</p>
<ul>
<li>
<p><strong>Encoder (Contraction Path)</strong>: Similar to FCN, the encoder part of U-Net captures high-level features through a series of convolutional and pooling layers. Each block typically consists of two 3x3 convolution layers followed by a ReLU activation function and a 2x2 max pooling layer.</p>
</li>
<li>
<p><strong>Decoder (Expansion Path)</strong>: The decoder part upscales the feature maps to the original image size using transposed convolutions. At each upsampling step, the decoder concatenates the feature maps from the corresponding encoder layer via skip connections, providing rich contextual information for precise segmentation.</p>
</li>
</ul>
<p><img loading="lazy" src="/posts/unet/img8.png" alt="Unet"  />
</p>
<h4 id="key-concepts-1">Key Concepts<a hidden class="anchor" aria-hidden="true" href="#key-concepts-1">#</a></h4>
<ul>
<li>
<p><strong>Skip Connections</strong>: By concatenating the feature maps from the encoder to the decoder at each corresponding level, U-Net can leverage both high-level and low-level features, resulting in better localization and segmentation accuracy.</p>
</li>
<li>
<p><strong>Data Augmentation</strong>: Given the often limited availability of annotated data in medical imaging, U-Net heavily relies on data augmentation techniques to enhance the diversity of the training dataset. This includes operations like rotations, flips, and elastic deformations.</p>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://adilsarsenov.dev/tags/beginner/">Beginner</a></li>
      <li><a href="https://adilsarsenov.dev/tags/image-segmentation/">Image Segmentation</a></li>
      <li><a href="https://adilsarsenov.dev/tags/deep-learning/">Deep Learning</a></li>
      <li><a href="https://adilsarsenov.dev/tags/fcn/">FCN</a></li>
      <li><a href="https://adilsarsenov.dev/tags/unet/">Unet</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://adilsarsenov.dev/">Adil&#39;s Notes</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>

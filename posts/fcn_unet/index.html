<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Image Segmentation Techniques: FCN and U-Net | Adil&#39;s Notes</title>
<meta name="keywords" content="Beginner, Image Segmentation, Deep Learning, FCN, Unet">
<meta name="description" content="FCN and U-Net.">
<meta name="author" content="">
<link rel="canonical" href="https://adilsarsenov.dev/posts/fcn_unet/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.a72801f0f40a8d7f71aa1cafd1c2f2a993a1f26ca1cfd38fdba65d5b9b0f08a0.css" integrity="sha256-pygB8PQKjX9xqhyv0cLyqZOh8myhz9OP26ZdW5sPCKA=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js" integrity="sha256-uVus3DnjejMqn4g7Hni&#43;Srwf3KK8HyZB9V4809q9TWE="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://adilsarsenov.dev/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://adilsarsenov.dev/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://adilsarsenov.dev/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://adilsarsenov.dev/apple-touch-icon.png">
<link rel="mask-icon" href="https://adilsarsenov.dev/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Image Segmentation Techniques: FCN and U-Net" />
<meta property="og:description" content="FCN and U-Net." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adilsarsenov.dev/posts/fcn_unet/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-04-01T18:34:44&#43;05:00" />
<meta property="article:modified_time" content="2024-04-01T18:34:44&#43;05:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Image Segmentation Techniques: FCN and U-Net"/>
<meta name="twitter:description" content="FCN and U-Net."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://adilsarsenov.dev/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Image Segmentation Techniques: FCN and U-Net",
      "item": "https://adilsarsenov.dev/posts/fcn_unet/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Image Segmentation Techniques: FCN and U-Net",
  "name": "Image Segmentation Techniques: FCN and U-Net",
  "description": "FCN and U-Net.",
  "keywords": [
    "Beginner", "Image Segmentation", "Deep Learning", "FCN", "Unet"
  ],
  "articleBody": "Introduction Image segmentation is a crucial technique in computer vision, enabling the division of an image into multiple meaningful and homogeneous regions or objects based on their inherent characteristics, such as color, texture, shape, or brightness. This process is fundamental in applications like object recognition, tracking, detection, medical imaging, and robotics. In this article, we delve into two powerful deep learning models for image segmentation: Fully Convolutional Networks (FCN) and U-Net. We will explore their architectures, key concepts, and practical applications, providing insights into their advantages and best practices for implementation.\nFully Convolutional Networks (FCN) Overview Fully Convolutional Networks (FCNs) are a class of neural networks designed specifically for semantic segmentation. Unlike traditional Convolutional Neural Networks (CNNs) that produce a single label for the entire image, FCNs output a segmentation map where each pixel is classified into a particular category.\nArchitecture The architecture of an FCN is based on an encoder-decoder structure:\nEncoder (Downsampling Path): This part of the network extracts complex features from the input image through a series of convolutional and pooling layers. The spatial resolution is reduced while increasing the depth of the feature maps, allowing the network to capture high-level semantic information.\nDecoder (Upsampling Path): The decoder part of the network upscales the reduced-resolution feature maps back to the original image size. This is achieved through transposed convolution layers (also known as deconvolution layers), which learn the appropriate strides and padding to reconstruct the high-resolution segmentation map.\nKey Concepts Pooling (Downsampling): Pooling layers reduce the spatial resolution of the feature maps, which helps in capturing invariant features and reducing computational complexity. Common types include max pooling and average pooling.\nTransposed Convolution (Upsampling): Transposed convolution layers are used to increase the spatial resolution of the feature maps, essentially reversing the effect of pooling layers to reconstruct the detailed segmentation map.\nSkip Connections: To address the loss of spatial information due to pooling, skip connections are introduced. These connections transfer features from the encoder directly to the corresponding decoder layers, enabling the network to recover fine-grained details and produce more accurate segmentation boundaries.\nPractical Implementation Here is a simplified implementation of an FCN using PyTorch:\nimport torch import torch.nn as nn class SimpleFCN(nn.Module): def __init__(self, n_classes): super(SimpleFCN, self).__init__() # Encoder: Downsampling part self.encoder = nn.Sequential( nn.Conv2d(3, 64, kernel_size=3, padding=1), # Conv layer nn.ReLU(), # Activation nn.MaxPool2d(kernel_size=2, stride=2), # Downsampling nn.Conv2d(64, 128, kernel_size=3, padding=1), # Conv layer nn.ReLU(), # Activation nn.MaxPool2d(kernel_size=2, stride=2) # Downsampling ) # Decoder: Upsampling part self.decoder = nn.Sequential( nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2), # Upsampling nn.ReLU(), # Activation nn.ConvTranspose2d(64, n_classes, kernel_size=2, stride=2) # Upsampling to original size ) def forward(self, x): x = self.encoder(x) x = self.decoder(x) return x model = SimpleFCN(n_classes=21) # Example with 21 classes U-Net Overview U-Net is a specialized neural network architecture designed for biomedical image segmentation, introduced by Olaf Ronneberger, Philipp Fischer, and Thomas Brox in 2015. Its distinctive U-shaped design, which features a symmetric encoder-decoder structure, has made it a popular choice in various medical image analysis tasks due to its impressive performance and efficiency.\nArchitecture The U-Net architecture consists of two main parts:\nEncoder (Contraction Path): Similar to FCN, the encoder part of U-Net captures high-level features through a series of convolutional and pooling layers. Each block typically consists of two 3x3 convolution layers followed by a ReLU activation function and a 2x2 max pooling layer.\nDecoder (Expansion Path): The decoder part upscales the feature maps to the original image size using transposed convolutions. At each upsampling step, the decoder concatenates the feature maps from the corresponding encoder layer via skip connections, providing rich contextual information for precise segmentation.\nKey Concepts Skip Connections: By concatenating the feature maps from the encoder to the decoder at each corresponding level, U-Net can leverage both high-level and low-level features, resulting in better localization and segmentation accuracy.\nData Augmentation: Given the often limited availability of annotated data in medical imaging, U-Net heavily relies on data augmentation techniques to enhance the diversity of the training dataset. This includes operations like rotations, flips, and elastic deformations.\nPractical Implementation Here is a simplified implementation of a U-Net using PyTorch:\nimport torch import torch.nn as nn import torch.nn.functional as F class SimpleUNet(nn.Module): def __init__(self, n_classes): super(SimpleUNet, self).__init__() # Encoder (Downsampling) self.enc1 = self.conv_block(3, 64) self.enc2 = self.conv_block(64, 128) self.enc3 = self.conv_block(128, 256) self.enc4 = self.conv_block(256, 512) # Decoder (Upsampling) self.upconv1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) self.dec1 = self.conv_block(512, 256) # 256 + 256 from skip connection self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) self.dec2 = self.conv_block(256, 128) # 128 + 128 from skip connection self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2) self.dec3 = self.conv_block(128, 64) # 64 + 64 from skip connection # Final layer self.final_conv = nn.Conv2d(64, n_classes, kernel_size=1) def conv_block(self, in_channels, out_channels): return nn.Sequential( nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1), nn.ReLU() ) def forward(self, x): # Encoder enc1 = self.enc1(x) enc2 = self.enc2(F.max_pool2d(enc1, 2)) enc3 = self.enc3(F.max_pool2d(enc2, 2)) enc4 = self.enc4(F.max_pool2d(enc3, 2)) # Decoder with skip connections dec1 = self.upconv1(enc4) dec1 = torch.cat((dec1, enc3), dim=1) # Concatenate skip connection dec1 = self.dec1(dec1) dec2 = self.upconv2(dec1) dec2 = torch.cat((dec2, enc2), dim=1) # Concatenate skip connection dec2 = self.dec2(dec2) dec3 = self.upconv3(dec2) dec3 = torch.cat((dec3, enc1), dim=1) # Concatenate skip connection dec3 = self.dec3(dec3) x = self.final_conv(dec3) return x model = SimpleUNet(n_classes=21) # Example with 21 classes Summary Both FCN and U-Net are powerful architectures for image segmentation tasks. FCN is a more general-purpose segmentation network, while U-Net is specifically designed for biomedical image segmentation with its U-shaped encoder-decoder structure and extensive use of skip connections.\n",
  "wordCount" : "920",
  "inLanguage": "en",
  "datePublished": "2024-04-01T18:34:44.165668+05:00",
  "dateModified": "2024-04-01T18:34:44.165668+05:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://adilsarsenov.dev/posts/fcn_unet/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Adil's Notes",
    "logo": {
      "@type": "ImageObject",
      "url": "https://adilsarsenov.dev/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top"><script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header sticky-header">
    <nav class="nav">
        <div class="logo">
            <a href="https://adilsarsenov.dev/" accesskey="h" title="Adil&#39;s Notes (Alt + H)">Adil&#39;s Notes</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://adilsarsenov.dev/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://adilsarsenov.dev/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://adilsarsenov.dev/">Home</a>&nbsp;»&nbsp;<a href="https://adilsarsenov.dev/posts/">Posts</a></div>
    <h1 class="post-title">
      Image Segmentation Techniques: FCN and U-Net
    </h1>
    <div class="post-description">
      FCN and U-Net.
    </div>
    <div class="post-meta">


Date: 01 April, 2024

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">‎ Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#fully-convolutional-networks-fcn" aria-label="Fully Convolutional Networks (FCN)">Fully Convolutional Networks (FCN)</a><ul>
                        
                <li>
                    <a href="#overview" aria-label="Overview">Overview</a></li>
                <li>
                    <a href="#architecture" aria-label="Architecture">Architecture</a></li>
                <li>
                    <a href="#key-concepts" aria-label="Key Concepts">Key Concepts</a></li>
                <li>
                    <a href="#practical-implementation" aria-label="Practical Implementation">Practical Implementation</a></li></ul>
                </li>
                <li>
                    <a href="#u-net" aria-label="U-Net">U-Net</a><ul>
                        
                <li>
                    <a href="#overview-1" aria-label="Overview">Overview</a></li>
                <li>
                    <a href="#architecture-1" aria-label="Architecture">Architecture</a></li>
                <li>
                    <a href="#key-concepts-1" aria-label="Key Concepts">Key Concepts</a></li>
                <li>
                    <a href="#practical-implementation-1" aria-label="Practical Implementation">Practical Implementation</a></li></ul>
                </li>
                <li>
                    <a href="#summary" aria-label="Summary">Summary</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Image segmentation is a crucial technique in computer vision, enabling the division of an image into multiple meaningful and homogeneous regions or objects based on their inherent characteristics, such as color, texture, shape, or brightness. This process is fundamental in applications like object recognition, tracking, detection, medical imaging, and robotics. In this article, we delve into two powerful deep learning models for image segmentation: Fully Convolutional Networks (FCN) and U-Net. We will explore their architectures, key concepts, and practical applications, providing insights into their advantages and best practices for implementation.</p>
<h2 id="fully-convolutional-networks-fcn">Fully Convolutional Networks (FCN)<a hidden class="anchor" aria-hidden="true" href="#fully-convolutional-networks-fcn">#</a></h2>
<h3 id="overview">Overview<a hidden class="anchor" aria-hidden="true" href="#overview">#</a></h3>
<p>Fully Convolutional Networks (FCNs) are a class of neural networks designed specifically for semantic segmentation. Unlike traditional Convolutional Neural Networks (CNNs) that produce a single label for the entire image, FCNs output a segmentation map where each pixel is classified into a particular category.</p>
<h3 id="architecture">Architecture<a hidden class="anchor" aria-hidden="true" href="#architecture">#</a></h3>
<p>The architecture of an FCN is based on an encoder-decoder structure:</p>
<ol>
<li>
<p><strong>Encoder (Downsampling Path)</strong>: This part of the network extracts complex features from the input image through a series of convolutional and pooling layers. The spatial resolution is reduced while increasing the depth of the feature maps, allowing the network to capture high-level semantic information.</p>
</li>
<li>
<p><strong>Decoder (Upsampling Path)</strong>: The decoder part of the network upscales the reduced-resolution feature maps back to the original image size. This is achieved through transposed convolution layers (also known as deconvolution layers), which learn the appropriate strides and padding to reconstruct the high-resolution segmentation map.</p>
</li>
</ol>
<h3 id="key-concepts">Key Concepts<a hidden class="anchor" aria-hidden="true" href="#key-concepts">#</a></h3>
<ul>
<li>
<p><strong>Pooling (Downsampling)</strong>: Pooling layers reduce the spatial resolution of the feature maps, which helps in capturing invariant features and reducing computational complexity. Common types include max pooling and average pooling.</p>
</li>
<li>
<p><strong>Transposed Convolution (Upsampling)</strong>: Transposed convolution layers are used to increase the spatial resolution of the feature maps, essentially reversing the effect of pooling layers to reconstruct the detailed segmentation map.</p>
</li>
<li>
<p><strong>Skip Connections</strong>: To address the loss of spatial information due to pooling, skip connections are introduced. These connections transfer features from the encoder directly to the corresponding decoder layers, enabling the network to recover fine-grained details and produce more accurate segmentation boundaries.</p>
</li>
</ul>
<h3 id="practical-implementation">Practical Implementation<a hidden class="anchor" aria-hidden="true" href="#practical-implementation">#</a></h3>
<p>Here is a simplified implementation of an FCN using PyTorch:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SimpleFCN</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, n_classes):
</span></span><span style="display:flex;"><span>        super(SimpleFCN, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Encoder: Downsampling part</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>encoder <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),  <span style="color:#75715e"># Conv layer</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),  <span style="color:#75715e"># Activation</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># Downsampling</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),  <span style="color:#75715e"># Conv layer</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),  <span style="color:#75715e"># Activation</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)  <span style="color:#75715e"># Downsampling</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Decoder: Upsampling part</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>decoder <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ConvTranspose2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># Upsampling</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),  <span style="color:#75715e"># Activation</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ConvTranspose2d(<span style="color:#ae81ff">64</span>, n_classes, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)  <span style="color:#75715e"># Upsampling to original size</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>decoder(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> SimpleFCN(n_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">21</span>)  <span style="color:#75715e"># Example with 21 classes</span>
</span></span></code></pre></div><h2 id="u-net">U-Net<a hidden class="anchor" aria-hidden="true" href="#u-net">#</a></h2>
<h3 id="overview-1">Overview<a hidden class="anchor" aria-hidden="true" href="#overview-1">#</a></h3>
<p>U-Net is a specialized neural network architecture designed for biomedical image segmentation, introduced by Olaf Ronneberger, Philipp Fischer, and Thomas Brox in 2015. Its distinctive U-shaped design, which features a symmetric encoder-decoder structure, has made it a popular choice in various medical image analysis tasks due to its impressive performance and efficiency.</p>
<h3 id="architecture-1">Architecture<a hidden class="anchor" aria-hidden="true" href="#architecture-1">#</a></h3>
<p>The U-Net architecture consists of two main parts:</p>
<ul>
<li>
<p><strong>Encoder (Contraction Path)</strong>: Similar to FCN, the encoder part of U-Net captures high-level features through a series of convolutional and pooling layers. Each block typically consists of two 3x3 convolution layers followed by a ReLU activation function and a 2x2 max pooling layer.</p>
</li>
<li>
<p><strong>Decoder (Expansion Path)</strong>: The decoder part upscales the feature maps to the original image size using transposed convolutions. At each upsampling step, the decoder concatenates the feature maps from the corresponding encoder layer via skip connections, providing rich contextual information for precise segmentation.</p>
</li>
</ul>
<h3 id="key-concepts-1">Key Concepts<a hidden class="anchor" aria-hidden="true" href="#key-concepts-1">#</a></h3>
<ul>
<li>
<p><strong>Skip Connections</strong>: By concatenating the feature maps from the encoder to the decoder at each corresponding level, U-Net can leverage both high-level and low-level features, resulting in better localization and segmentation accuracy.</p>
</li>
<li>
<p><strong>Data Augmentation</strong>: Given the often limited availability of annotated data in medical imaging, U-Net heavily relies on data augmentation techniques to enhance the diversity of the training dataset. This includes operations like rotations, flips, and elastic deformations.</p>
</li>
</ul>
<h3 id="practical-implementation-1">Practical Implementation<a hidden class="anchor" aria-hidden="true" href="#practical-implementation-1">#</a></h3>
<p>Here is a simplified implementation of a U-Net using PyTorch:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">SimpleUNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, n_classes):
</span></span><span style="display:flex;"><span>        super(SimpleUNet, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Encoder (Downsampling)</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>enc1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">64</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>enc2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">128</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>enc3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">256</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>enc4 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">512</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Decoder (Upsampling)</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>upconv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ConvTranspose2d(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dec1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">256</span>)  <span style="color:#75715e"># 256 + 256 from skip connection</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>upconv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ConvTranspose2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dec2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">128</span>)  <span style="color:#75715e"># 128 + 128 from skip connection</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>upconv3 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ConvTranspose2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>dec3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv_block(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">64</span>)   <span style="color:#75715e"># 64 + 64 from skip connection</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Final layer</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>final_conv <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">64</span>, n_classes, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">conv_block</span>(self, in_channels, out_channels):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(in_channels, out_channels, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(out_channels, out_channels, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU()
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Encoder</span>
</span></span><span style="display:flex;"><span>        enc1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>enc1(x)
</span></span><span style="display:flex;"><span>        enc2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>enc2(F<span style="color:#f92672">.</span>max_pool2d(enc1, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>        enc3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>enc3(F<span style="color:#f92672">.</span>max_pool2d(enc2, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>        enc4 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>enc4(F<span style="color:#f92672">.</span>max_pool2d(enc3, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Decoder with skip connections</span>
</span></span><span style="display:flex;"><span>        dec1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>upconv1(enc4)
</span></span><span style="display:flex;"><span>        dec1 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat((dec1, enc3), dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)  <span style="color:#75715e"># Concatenate skip connection</span>
</span></span><span style="display:flex;"><span>        dec1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dec1(dec1)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        dec2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>upconv2(dec1)
</span></span><span style="display:flex;"><span>        dec2 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat((dec2, enc2), dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)  <span style="color:#75715e"># Concatenate skip connection</span>
</span></span><span style="display:flex;"><span>        dec2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dec2(dec2)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        dec3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>upconv3(dec2)
</span></span><span style="display:flex;"><span>        dec3 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat((dec3, enc1), dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)  <span style="color:#75715e"># Concatenate skip connection</span>
</span></span><span style="display:flex;"><span>        dec3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>dec3(dec3)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>final_conv(dec3)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> SimpleUNet(n_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">21</span>)  <span style="color:#75715e"># Example with 21 classes</span>
</span></span></code></pre></div><h2 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h2>
<p>Both FCN and U-Net are powerful architectures for image segmentation tasks. FCN is a more general-purpose segmentation network, while U-Net is specifically designed for biomedical image segmentation with its U-shaped encoder-decoder structure and extensive use of skip connections.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://adilsarsenov.dev/tags/beginner/">Beginner</a></li>
      <li><a href="https://adilsarsenov.dev/tags/image-segmentation/">Image Segmentation</a></li>
      <li><a href="https://adilsarsenov.dev/tags/deep-learning/">Deep Learning</a></li>
      <li><a href="https://adilsarsenov.dev/tags/fcn/">FCN</a></li>
      <li><a href="https://adilsarsenov.dev/tags/unet/">Unet</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://adilsarsenov.dev/">Adil&#39;s Notes</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
